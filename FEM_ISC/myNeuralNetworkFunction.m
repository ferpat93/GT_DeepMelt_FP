function [Y,Xf,Af] = myNeuralNetworkFunction(X,~,~)
%MYNEURALNETWORKFUNCTION neural network simulation function.
%
% Auto-generated by MATLAB, 08-Sep-2019 21:03:53.
%
% [Y] = myNeuralNetworkFunction(X,~,~) takes these arguments:
%
%   X = 1xTS cell, 1 inputs over TS timesteps
%   Each X{1,ts} = Qx5 matrix, input #1 at timestep ts.
%
% and returns:
%   Y = 1xTS cell of 1 outputs over TS timesteps.
%   Each Y{1,ts} = Qx3 matrix, output #1 at timestep ts.
%
% where Q is number of samples (or series) and TS is the number of timesteps.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1.xoffset = [20000000;0.15;25;6.25;0.25];
x1_step1.gain = [2.5e-08;6.66666666666667;0.1;0.0727272727272727;4];
x1_step1.ymin = -1;

% Layer 1
b1 = [-2.2573509230964718952;-2.4448815584343108753;1.6598279338190056187;-2.1979371005133301331;-0.98305262353356404059;0.35982131494077207456;1.5064970005746316506;-1.7149272824607364463;-1.5849854965778877869;-1.6458238323273544079];
IW1_1 = [1.4542976098143656216 -0.98301472797134448189 0.54413527061737276824 0.59290111570747039416 -1.2601504247430619365;2.0569642770870486537 -2.2457852839811485168 -0.28158386449166439292 0.26399807974267930355 -0.27683177801677877339;-1.257875733095728199 1.1946353503548385877 -0.81260739441843066189 1.0470092721561417015 1.1237937314262325117;0.083287892546744846101 3.5381660701609458641 0.967838308994520502 0.095082070265378890173 0.092575656708748121915;1.775664049742649464 -0.015109016811327390106 -0.93981624189867296604 1.2571121483057063895 0.29931946456176461435;-2.8914663151859962831 5.6599154244934526403 1.1969136254375365436 -0.0007684978457229499349 0.17792261956834762304;0.96986195057914870166 2.5156073249537813652 0.047620446252952051969 0.079753007404126302626 -0.14769628435530346433;0.088013759951272391158 -1.5003077278244423276 -0.70180878817065628361 -0.66032357048445777803 -1.4003542204671568516;-2.2014974716590440806 1.8235785199462557493 -0.066983892116544457851 1.1756151810236281641 -0.39366102226875648862;0.17857216009639143017 0.045303930724661531371 -2.0788278995192657206 -0.93511738647839748317 1.1627642977915684241];

% Layer 2
b2 = [2.276102085466137126;-0.8220725300691064108;-1.1800564943025741993];
LW2_1 = [0.83031037735808699285 -1.1649021853635774804 -0.5728570874417191483 1.8871072315159354016 0.3596919142091365984 -3.1907764651893959496 -0.30451700615103399761 0.28028897583277884165 0.25595621001770590963 -0.43726243708169248992;0.1687905436107086099 2.0214320182579106344 -0.038946692024817687605 -0.49288672861236942913 -0.5802956972314693429 0.74219373063821569847 1.2572454436138154055 0.2403662935779624088 -0.28145277415440056457 -0.30501311717526230494;0.96674310386297657161 -1.4267551557594939649 0.16841241435738657506 -1.5650856628232845402 0.18326896804895159709 1.9475186957360817175 -1.2142766850559665315 0.72976541442600939558 -1.4752045223512908478 -0.42808292954043319911];

% ===== SIMULATION ========

% Format Input Arguments
isCellX = iscell(X);
if ~isCellX
    X = {X};
end

% Dimensions
TS = size(X,2); % timesteps
if ~isempty(X)
    Q = size(X{1},1); % samples/series
else
    Q = 0;
end

% Allocate Outputs
Y = cell(1,TS);

% Time loop
for ts=1:TS
    
    % Input 1
    X{1,ts} = X{1,ts}';
    Xp1 = mapminmax_apply(X{1,ts},x1_step1);
    
    % Layer 1
    a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*Xp1);
    
    % Layer 2
    a2 = softmax_apply(repmat(b2,1,Q) + LW2_1*a1);
    
    % Output 1
    Y{1,ts} = a2;
    Y{1,ts} = Y{1,ts}';
end

% Final Delay States
Xf = cell(1,0);
Af = cell(2,0);

% Format Output Arguments
if ~isCellX
    Y = cell2mat(Y);
end
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings)
y = bsxfun(@minus,x,settings.xoffset);
y = bsxfun(@times,y,settings.gain);
y = bsxfun(@plus,y,settings.ymin);
end

% Competitive Soft Transfer Function
function a = softmax_apply(n,~)
if isa(n,'gpuArray')
    a = iSoftmaxApplyGPU(n);
else
    a = iSoftmaxApplyCPU(n);
end
end
function a = iSoftmaxApplyCPU(n)
nmax = max(n,[],1);
n = bsxfun(@minus,n,nmax);
numerator = exp(n);
denominator = sum(numerator,1);
denominator(denominator == 0) = 1;
a = bsxfun(@rdivide,numerator,denominator);
end
function a = iSoftmaxApplyGPU(n)
nmax = max(n,[],1);
numerator = arrayfun(@iSoftmaxApplyGPUHelper1,n,nmax);
denominator = sum(numerator,1);
a = arrayfun(@iSoftmaxApplyGPUHelper2,numerator,denominator);
end
function numerator = iSoftmaxApplyGPUHelper1(n,nmax)
numerator = exp(n - nmax);
end
function a = iSoftmaxApplyGPUHelper2(numerator,denominator)
if (denominator == 0)
    a = numerator;
else
    a = numerator ./ denominator;
end
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n,~)
a = 2 ./ (1 + exp(-2*n)) - 1;
end
